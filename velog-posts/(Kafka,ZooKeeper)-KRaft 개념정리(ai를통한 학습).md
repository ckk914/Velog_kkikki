<blockquote>
<p>개인 정보 수집 (with ai)</p>
</blockquote>
<p>현재 상태 (2024년 11월 기준)
프로덕션 사용 가능
Kafka 3.3 버전부터 KRaft를 프로덕션 환경에서 공식적으로 사용할 수 있습니다2
현재 AWS MSK에서도 Kafka 3.7 버전부터 KRaft 모드를 지원합니다1
ZooKeeper 사용 여부
현재는 KRaft와 ZooKeeper 모드 둘 다 선택적으로 사용 가능합니다
새로운 클러스터를 구축할 때는 KRaft 모드 사용이 권장됩니다3
ZooKeeper는 Kafka 4.0(2024년 예정)에서 완전히 제거될 예정입니다34
장점
KRaft 모드 사용시
브로커 수를 최대 60개까지 확장 가능 (ZooKeeper 모드는 30개 제한)1
운영 복잡성 감소
메타데이터 처리 성능 향상
클러스터 관리가 더 간단해짐
따라서, 현재 새로운 Kafka 클러스터를 구축한다면 KRaft 모드를 사용하는 것이 좋으며, 기존 ZooKeeper 기반 클러스터는 계획적인 마이그레이션을 준비하는 것이 바람직합니다.</p>
<hr />
<p>Kafka 3.x 버전대
3.0 버전
KRaft가 처음 도입되었으나 아직 프로덕션 사용 권장하지 않음3
기본 설정 변경: Producer의 강력한 전달 보장 기능 활성화(acks=all, enable.idempotence=true)3
Consumer의 session.timeout.ms 기본값이 10초에서 45초로 증가3
3.1 버전
KRaft 기능 개선 및 버그 수정4
Topic ID 지원 추가로 안전성 향상4
OpenID 인증 제공자 연동 지원4
3.5 버전
ZooKeeper가 공식적으로 Deprecated 선언5
Rack-aware 파티션 할당 기능 추가5
SCRAM 인증 지원으로 KRaft 보안 강화5
상태 저장소의 버전 관리 기능 추가5
향후 계획
4.0 버전 (예정)
ZooKeeper 완전 제거 예정
KRaft만 사용 가능
완전한 메타데이터 관리 시스템으로 전환
권장사항
현재 프로덕션 환경
3.5.1 버전 사용 권장1
ZooKeeper 모드에서 KRaft로의 전환 준비 필요
대규모 환경의 경우 안정성을 위해 ZooKeeper 모드 유지 고려
신규 환경
최신 버전(3.6.0 이상) 사용 권장1
KRaft 모드로 시작하는 것이 향후 마이그레이션 부담을 줄일 수 있음</p>
<hr />
<p>답변
검색 결과를 바탕으로 Kafka 3.5.1 버전의 KRaft 사용에 대해 정확히 설명해드리겠습니다.
Kafka 3.5.1의 KRaft 상태
제한적 사용 가능
3.5.1 버전에서 KRaft는 Public Preview 상태로만 제공됩니다3
프로덕션 환경에서는 여전히 ZooKeeper 모드가 권장됩니다3
새로운 클러스터 생성 시 ZooKeeper 모드가 기본값입니다3
주요 제한사항
ZooKeeper에서 KRaft로의 무중단 마이그레이션이 아직 Early Access 기능입니다3
프로덕션 환경에서는 권장되지 않습니다3
완전한 기능 지원은 Kafka 3.6 버전에서 예상됩니다3
권장사항
신규 환경
테스트 환경에서는 KRaft 모드를 사용해볼 수 있습니다
프로덕션 환경에서는 ZooKeeper 모드로 시작하는 것이 안전합니다
기존 환경
ZooKeeper 모드를 유지하면서 KRaft 전환을 위한 준비를 하는 것이 좋습니다
Kafka 4.0 출시 전까지 안정적인 마이그레이션 계획을 수립해야 합니다</p>
<hr />
<ul>
<li><h2 id="ai-활용-내용정리">ai 활용 내용정리</h2>
</li>
</ul>
<blockquote>
<p>메시지큐인 Kafka를 운영하려면 원래 두 개의 시스템이 필요했습니다:
Kafka: 실제 메시지를 주고받는 시스템
ZooKeeper: Kafka의 설정과 상태를 관리하는 시스템</p>
</blockquote>
<p>KRaft는 ZooKeeper를 제거하고 Kafka 안에 직접 관리 기능을 넣은 것입니다.
마치 비서(ZooKeeper)를 없애고 직접 관리하기로 한 것과 같습니다.</p>
<h3 id="동작-방식">동작 방식</h3>
<blockquote>
<p>컨트롤러 구조
기존에는 1개였던 관리자(컨트롤러)를 3개로 늘립니다
3명의 관리자 중 1명이 리더가 되어 실제 관리를 담당합니다
리더가 문제가 생기면 나머지 2명 중에서 새로운 리더를 투표로 뽑습니다</p>
</blockquote>
<h3 id="메타데이터-관리">메타데이터 관리</h3>
<p>모든 설정과 상태 정보를 Kafka 내부의 특별한 토픽에 저장합니다
컨트롤러들은 이 정보를 메모리에 캐시해두어 빠르게 접근할 수 있습니다
리더가 바뀌어도 메모리에 정보가 있어서 빠르게 전환이 가능합니다</p>
<h3 id="성능-개선">성능 개선</h3>
<p>외부 시스템과의 통신이 없어져서 처리 속도가 빨라졌습니다
더 많은 파티션을 처리할 수 있게 되었습니다
시스템 장애 시 복구 시간이 크게 단축되었습니다</p>
<hr />
<p>zookeeper 이 놈은 한마디로 카프카 서버 상태를 관리하는 애
분산 코디네이터이다.</p>
<p>그리고 그건 kraft도 마찬가지다.
kafka는 오랫동안 의존했던 zookeeper를 통해 했는 일을 Raft 합의 프로토콜을 사용해서 KRaft로 자체적으로 관리하게 된거다.</p>
<hr />
<p>내가 이해한대로 적다보니 상대적으로 내용이 적지만 뭐든지 직접 해봐야 완전히 이해할 수 있는거다.
ㄴ맞말..</p>
<hr />
<p>카프카의 핵심 용어</p>
<h3 id="클러스터">클러스터</h3>
<p>클러스터의 개념을 쉽게 설명해드리겠습니다.
기본 개념
클러스터는 '무리' 또는 '집단'이라는 의미로, 여러 개의 시스템이 모여 하나의 시스템처럼 동작하는 구조를 말합니다1.
주요 특징
동작 방식
여러 대의 컴퓨터가 네트워크로 연결되어 하나의 시스템처럼 작동합니다
작업을 여러 시스템에 분산하여 처리할 수 있습니다
한 시스템이 문제가 생겨도 다른 시스템이 대신 작업을 처리할 수 있습니다
장점
단일 컴퓨터보다 더 뛰어난 성능과 안정성을 제공합니다
비용 효율적입니다
필요에 따라 시스템을 추가하여 확장이 쉽습니다1
활용 분야
주요 사용처
웹 서비스: 수많은 사용자 요청 처리
데이터 처리: 대용량 데이터 분석
고가용성 시스템: 무중단 서비스 제공
과학 계산: 복잡한 연산 처리6
클러스터는 마치 여러 명의 직원이 협력하여 하나의 큰 작업을 처리하는 것과 같은 방식으로 작동한다고 이해하시면 됩니다.'
브로커를 여러개를 모은 클러스터로 보면 됨</p>
<h3 id="브로커-broker">브로커 (Broker)</h3>
<p>우체국의 우체통이라고 생각하면 됩니다
메시지를 보관하고 전달하는 서버입니다
여러 개의 우체통(브로커)이 모여서 하나의 카프카 시스템을 만듭니다</p>
<h3 id="토픽-topic">토픽 (Topic)</h3>
<p>우체통 안의 분류함이라고 생각하면 됩니다
예를 들어 "급한 편지", "일반 편지" 처럼 메시지를 종류별로 구분하는 공간입니다</p>
<h3 id="프로듀서-producer">프로듀서 (Producer)</h3>
<p>편지를 보내는 사람입니다
메시지를 만들어서 카프카에 보내는 프로그램입니다</p>
<h3 id="컨슈머-consumer">컨슈머 (Consumer)</h3>
<p>편지를 받는 사람입니다
카프카에서 메시지를 가져가서 읽는 프로그램입니다</p>
<h3 id="파티션-partition">파티션 (Partition)</h3>
<p>하나의 분류함을 여러 개로 나눈 작은 칸입니다
많은 편지를 효율적으로 처리하기 위해 나눠놓은 공간입니다</p>
<h3 id="메시지-message">메시지 (Message)</h3>
<p>실제 주고받는 편지의 내용입니다
프로그램들이 주고받는 데이터입니다
이렇게 카프카는 마치 우체국처럼 메시지를 주고받는 시스템이라고 이해하면 됩니다!</p>
<hr />
<h3 id="추가-요소">추가 요소</h3>
<p>Conduktor – 그래픽 UI를 통해 Kafka 활용하는 방법 (모니터링 및 관리 툴)
Kafka Connect
데이터베이스, 키-값 저장소, 검색 인덱스 및 파일 시스템 간의 간단한 데이터 통합을 위한 중앙 집중식 데이터 허브 역할을 하는 Apache Kafka의 무료 오픈소스 구성요소
Kafka Streams
 Kafka Streams는 입력 스트림의 파티션 개수만큼 태스크를 생성하고 각 스트림의 파티션은 카프카의 토픽 파티션에 저장된 정렬된 메시지
Confluent Schema Registry
RESTful 인터페이스를 사용하여 스키마(Schema)를 관리하거나 조회하는 기능을 제공
Kafka Architectrue
카프카 클러스터를 중심으로 프로듀서와 컨슈머가 데이터를 push하고 pull하는 구조</p>
<hr />
<p>카프카의 실제 사용 사례를 쉽게 설명해드리겠습니다.
실생활 예시로 보는 카프카 활용</p>
<ol>
<li>배달의 민족 주문 시스템
고객이 주문을 하면(Producer) → 카프카가 받아서 → 가게, 라이더, 결제시스템(Consumers)에 동시에 알려줍니다
마치 단체 채팅방에서 한 명이 메시지를 보내면 모든 사람이 동시에 받는 것처럼 작동합니다</li>
<li>넷플릭스 시청 기록
사용자가 영화를 볼 때마다(Producer) → 카프카가 받아서 → 추천 시스템, 인기 순위 시스템, 결제 시스템(Consumers)에 동시에 전달합니다
하나의 시청 기록이 여러 시스템에서 동시에 활용됩니다</li>
<li>은행 거래 시스템
계좌 이체가 발생하면(Producer) → 카프카가 받아서 → 거래 기록, 알림 발송, 사기 탐지 시스템(Consumers)으로 전달합니다
하나의 거래 정보가 여러 시스템에서 필요할 때 유용합니다
카프카가 유용한 상황</li>
<li>대량의 데이터를 실시간으로 처리할 때
예: SNS에서 게시물 좋아요, 댓글 등의 실시간 반영</li>
<li>여러 시스템이 하나의 데이터를 필요로 할 때
예: 상품 주문 정보가 배송, 결제, 재고 시스템에 모두 필요한 경우</li>
<li>시스템 장애가 발생해도 데이터를 잃으면 안 될 때
예: 금융 거래 데이터처럼 중요한 정보를 안전하게 전달해야 할 때
카프카는 마치 우체국처럼 메시지를 안전하게 보관했다가 필요한 곳에 배달해주는 시스템</li>
</ol>
<hr />
<h3 id="메시지-순서-보장-조건">메시지 순서 보장 조건</h3>
<p>동일한 키를 가진 메시지
같은 키를 가진 메시지는 항상 동일한 파티션으로 전송됩니다1
같은 키의 메시지들은 보낸 순서대로 처리됩니다2
예: 사용자 ID를 키로 사용하면, 특정 사용자의 모든 메시지는 순서가 보장됩니다
파티션 내부
하나의 파티션 내에서는 메시지 순서가 완벽하게 보장됩니다4
서로 다른 파티션 간의 순서는 보장되지 않습니다4
주의사항
순서 보장을 위한 설정
Producer 설정에서 acks=all 설정이 필요합니다2
Producer의 멱등성(idempotence) 활성화가 필요합니다2
키를 사용한 메시지 전송이 필요합니다2
파티션 수 변경
파티션 수를 변경하면 순서 보장이 깨질 수 있습니다3
운영 중인 시스템에서는 파티션 수 변경을 피해야 합니다3</p>
<hr />
<h3 id="주의해야-할-핵심-사항들을-정리">주의해야 할 핵심 사항들을 정리</h3>
<p>데이터 관리 관련
데이터 보존 설정
데이터 보존 기간과 용량을 적절히 설정해야 합니다1
디스크 용량이 가득 차지 않도록 관리가 필요합니다1
기본 설정인 7일 보존 기간을 그대로 사용하면 문제가 될 수 있습니다5
토픽과 파티션 관리
파티션은 8~20개로 설정하고 처리 속도에 따라 조절이 필요합니다1
파티션이 여러 개일 때는 메시지 순서가 보장되지 않을 수 있습니다1
메시지 순서가 중요한 서비스는 파티션을 1개로 설정하거나 다른 방법을 찾아야 합니다1
성능과 안정성
요청 수 제어
데이터양보다 요청 수(request quota)를 제어하는 것이 중요합니다1
한 토픽으로 메시지가 몰려도 다른 작업에 영향이 가지 않도록 설정해야 합니다1
보안 설정
기본 설정을 그대로 사용하면 보안에 취약할 수 있습니다2
SSL 설정, 인증, 접근 제어 목록(ACL) 설정이 필요합니다2
정기적인 보안 감사가 필요합니다2
운영 관련
모니터링과 장애 대비
주요 브로커 메트릭을 모니터링해야 합니다3
재해 복구 계획이 반드시 필요합니다6
장애 발생 시를 대비한 복제 설정이 중요합니다4
확장성 고려
장기 저장소 계획이 필요합니다6
클러스터 확장 시 토픽 밸런싱을 고려해야 합니다6
API 사용량 제어가 필요합니다6
이러한 주의사항들을 고려하여 카프카를 설계하고 운영하면 안정적인 시스템을 구축할 수 있습니다.</p>
<hr />
<h3 id="파티션-설정">파티션 설정</h3>
<p>카프카 파티션 개수 설정에 대해 실용적으로 설명해드리겠습니다.
기본 권장사항
일반적인 규칙
토픽당 10개의 파티션이 기본 권장됩니다
전체 카프카 클러스터당 10,000개 파티션 이하가 좋습니다
브로커당 4,000개 이하의 파티션을 유지하는 것이 좋습니다3
파티션 개수 계산 방법
간단한 계산식
text
필요한 파티션 수 = 원하는 처리량 / 파티션 처리 속도</p>
<p>예시 계산
단일 파티션은 약 10MB/s 처리 가능
만약 하루 5TB 처리가 필요하다면 (58MB/s)
필요 파티션 수 = 58MB/s ÷ 10MB/s = 약 6개 파티션4
고려해야 할 사항
성능 관련
파티션이 많을수록 파일 디스크립터 수가 증가합니다
너무 많은 파티션은 ZooKeeper에 부담을 줄 수 있습니다
파티션 수를 줄이는 것은 지원되지 않으므로, 처음부터 신중하게 설정해야 합니다3
실제 운영시
처음에는 보수적으로 설정하고 모니터링하면서 조정하는 것이 좋습니다
파티션 재할당은 비용이 많이 들기 때문에, 부족한 것보다는 여유있게 설정하는 것이 좋습니다
키 기반 파티션의 수 변경은 수동 복사가 필요하므로 매우 복잡합니다</p>
<hr />